---
title: Thought Experiments
---

## Introduction

This is a sketchpad for some [thought experiments](https://en.wikipedia.org/wiki/Thought_experiment).

## Exotic Sensory Modalities

Artificial-intelligence systems can [perceive](https://en.wikipedia.org/wiki/Machine_perception) and [integrate](https://en.wikipedia.org/wiki/Multisensory_integration) data from kinds of sensors beyond those corresponding with human visual, auditory, vestibular, olfactory, gustatory, and somatosensory senses.

Examples of [nonhuman animal sensation and perception](https://en.wikipedia.org/wiki/Sense#Nonhuman_animal_sensation_and_perception) include [electroreception](https://en.wikipedia.org/wiki/Electroreception), [magnetoreception](https://en.wikipedia.org/wiki/Magnetoreception), [echolocation](https://en.wikipedia.org/wiki/Animal_echolocation), [hygroreception](https://en.wikipedia.org/wiki/Hygroreception), and [infrared sensing](https://en.wikipedia.org/wiki/Infrared_sensing_in_snakes).

Kinds of [sensors](https://en.wikipedia.org/wiki/Sensor) include [automotive](https://en.wikipedia.org/wiki/List_of_sensors#Automotive), [acoustic, sound, and vibration](https://en.wikipedia.org/wiki/List_of_sensors#Acoustic,_sound,_vibration), [chemical](https://en.wikipedia.org/wiki/List_of_sensors#Chemical), [electric current, electric potential, magnetic, and radio](https://en.wikipedia.org/wiki/List_of_sensors#Electric_current,_electric_potential,_magnetic,_radio), [environment, weather, moisture, and humidity](https://en.wikipedia.org/wiki/List_of_sensors#Environment,_weather,_moisture,_humidity), [flow, fluid, and velocity](https://en.wikipedia.org/wiki/List_of_sensors#Flow,_fluid_velocity), [ionizing radiation and subatomic particles](https://en.wikipedia.org/wiki/List_of_sensors#Ionizing_radiation,_subatomic_particles), [navigation instruments](https://en.wikipedia.org/wiki/List_of_sensors#Navigation_instruments), [position, angle, displacement, distance, speed, and acceleration](https://en.wikipedia.org/wiki/List_of_sensors#Position,_angle,_displacement,_distance,_speed,_acceleration), [optical, light, imaging, and photon](https://en.wikipedia.org/wiki/List_of_sensors#Optical,_light,_imaging,_photon), [pressure](https://en.wikipedia.org/wiki/List_of_sensors#Pressure), [force, density, and level](https://en.wikipedia.org/wiki/List_of_sensors#Force,_density,_level), [thermal, heat, and temperature](https://en.wikipedia.org/wiki/List_of_sensors#Thermal,_heat,_temperature), [proximity and presence](https://en.wikipedia.org/wiki/List_of_sensors#Proximity,_presence), [sensor technology](https://en.wikipedia.org/wiki/List_of_sensors#Sensor_technology), [speed](https://en.wikipedia.org/wiki/List_of_sensors#Speed_sensor), and [more](https://en.wikipedia.org/wiki/List_of_sensors#Others).

## Higher-dimensional Sensory Modalities

What if artificial-intelligence systems could perceive, navigate, and explore [simulated](https://en.wikipedia.org/wiki/Computer_simulation) higher-dimensional environments?

How might sensors work for higher-dimensional spaces? For [four-dimensional spaces](https://en.wikipedia.org/wiki/Four-dimensional_space), might four-dimensional [lenses](https://en.wikipedia.org/wiki/Lens) [focus](https://en.wikipedia.org/wiki/Focus_(optics)) incoming rays onto three-dimensional [retinas](https://en.wikipedia.org/wiki/Retina)?

Can artificial-intelligence systems, e.g., artificial neural networks, learn to control attached sensors and to navigate in higher-dimensional spaces, perceiving and comprehending these environments?
